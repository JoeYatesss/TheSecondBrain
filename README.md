# üß† Second Brain

> A personal knowledge assistant that ingests everything you learn and becomes an AI that "thinks like you."

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![LangGraph](https://img.shields.io/badge/LangGraph-Agents-orange.svg)](https://langchain-ai.github.io/langgraph/)

---

## üìñ Overview

Second Brain is an AI-powered knowledge management system that:

- **Ingests** your notes, articles, PDFs, and web content
- **Understands** relationships between concepts using embeddings and vector search
- **Answers** questions using RAG (Retrieval-Augmented Generation)
- **Acts** as an intelligent agent that can search, browse, and take notes for you

This project is designed as a learning journey through AI engineering, progressing from beginner concepts to advanced production systems.

---

## üéØ Features

- üí¨ Conversational AI with memory and streaming
- üìÑ Multi-format document ingestion (PDF, Markdown, Web, Images)
- üîç Semantic search with caching and hybrid retrieval
- ü§ñ Autonomous agent with tool use and intent routing
- üõ°Ô∏è Production guardrails and safety measures
- üìä Comprehensive evaluation and observability
- üí∞ Cost tracking and model routing
- üöÄ Production-ready API with local model support

---

## üó∫Ô∏è Project Roadmap

This project is structured in 8 phases, each building on the previous:

| Phase | Focus | Status |
|-------|-------|--------|
| [Phase 1](#phase-1-basic-chat-api) | Basic Chat API | üî≤ Not Started |
| [Phase 2](#phase-2-prompt-engineering--memory) | Prompt Engineering & Memory | üî≤ Not Started |
| [Phase 3](#phase-3-document-ingestion--chunking) | Document Ingestion & Chunking | üî≤ Not Started |
| [Phase 4](#phase-4-embeddings--vector-database) | Embeddings & Vector Database | üî≤ Not Started |
| [Phase 5](#phase-5-rag-pipeline) | RAG Pipeline | üî≤ Not Started |
| [Phase 6](#phase-6-agents--tools-with-langgraph) | Agents & Tools with LangGraph | üî≤ Not Started |
| [Phase 7](#phase-7-advanced-retrieval--evaluation) | Advanced Retrieval & Evaluation | üî≤ Not Started |
| [Phase 8](#phase-8-custom-models--production) | Custom Models & Production | üî≤ Not Started |

---

## üèóÔ∏è Architecture

```
Phase 1-2:  User ‚Üí LLM API ‚Üí Response

Phase 3-5:  User ‚Üí Guardrails ‚Üí Retriever ‚Üí Vector DB
                                    ‚Üì
                                LLM API ‚Üí Response

Phase 6+:   User ‚Üí Guardrails ‚Üí Intent Classifier
                                    ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚Üì               ‚Üì               ‚Üì
                Simple Q&A    RAG Pipeline    Agent (LangGraph)
                    ‚Üì               ‚Üì               ‚Üì
                    ‚îÇ               ‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ               ‚îÇ       ‚Üì       ‚Üì       ‚Üì
                    ‚îÇ               ‚îÇ    Search   Tools   RAG
                    ‚Üì               ‚Üì       ‚Üì       ‚Üì       ‚Üì
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚Üì
                            Model Router
                                    ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚Üì               ‚Üì               ‚Üì
                Haiku           Sonnet          Local
              (Simple)        (Complex)       (Private)
                    ‚Üì               ‚Üì               ‚Üì
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚Üì
                    Cache ‚Üí Response ‚Üí Feedback Loop
```

---

## üß† AI Engineering Concepts Covered

| Category | Concepts |
|----------|----------|
| **Core LLM** | API calls, streaming, prompting, structured outputs, token management |
| **RAG** | Chunking, embeddings, vector DBs, retrieval, reranking, hybrid search |
| **Agents** | LangGraph, tool use, ReAct pattern, state management, intent routing |
| **Safety** | Guardrails, input validation, PII detection, prompt injection defense |
| **Optimization** | Caching (semantic + exact), model routing, cost tracking |
| **Evaluation** | RAGAS, LLM-as-judge, synthetic data generation, A/B testing |
| **ML Training** | Embedding fine-tuning, contrastive learning, distillation basics |
| **Production** | FastAPI, observability, local models, feedback loops, batch processing |

---

## üìö Phase Details

### Phase 1: Basic Chat API
**Timeline:** Week 1 | **Difficulty:** Beginner

Build a CLI chatbot with streaming responses and proper error handling.

**Learning Objectives:**
- API authentication and requests
- Prompt structure (system/user/assistant)
- Streaming responses (real-time token output)
- Error handling with exponential backoff
- Retry logic and fallback strategies
- Graceful degradation patterns

**Key Files:**
```
src/
‚îú‚îÄ‚îÄ chat.py              # Basic chat implementation
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ streaming.py     # Stream handling utilities
    ‚îî‚îÄ‚îÄ retry.py         # Retry logic with backoff
```
---

### Phase 2: Prompt Engineering & Memory
**Timeline:** Week 2-3 | **Difficulty:** Beginner

Add conversation memory, structured outputs, and cost awareness.

**Learning Objectives:**
- Context window management
- Few-shot prompting techniques
- System prompt design
- Structured outputs with Pydantic
- Token counting and truncation strategies
- Cost tracking per conversation

**Key Files:**
```
src/
‚îú‚îÄ‚îÄ chat.py
‚îú‚îÄ‚îÄ memory.py            # Conversation history management
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ templates.py     # Prompt templates
‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îî‚îÄ‚îÄ outputs.py       # Pydantic output models
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ tokens.py        # Token counting utilities
    ‚îî‚îÄ‚îÄ costs.py         # Cost tracking
```
---

### Phase 3: Document Ingestion & Chunking
**Timeline:** Weeks 4-5 | **Difficulty:** Intermediate

Ingest documents including multi-modal content with batch processing.

**Learning Objectives:**
- Text extraction (PyMuPDF, BeautifulSoup)
- Image extraction and processing
- Chunking strategies (fixed, recursive, semantic)
- Metadata extraction and preservation
- Understanding chunk size and overlap tradeoffs
- Batch processing for large document sets
- Async patterns for parallel ingestion

**Key Files:**
```
src/
‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îú‚îÄ‚îÄ pdf.py           # PDF extraction (text + images)
‚îÇ   ‚îú‚îÄ‚îÄ markdown.py      # Markdown processing
‚îÇ   ‚îú‚îÄ‚îÄ web.py           # Web scraping
‚îÇ   ‚îú‚îÄ‚îÄ images.py        # Image handling for multi-modal
‚îÇ   ‚îî‚îÄ‚îÄ batch.py         # Batch processing orchestration
‚îî‚îÄ‚îÄ chunking/
    ‚îú‚îÄ‚îÄ fixed.py         # Fixed-size chunking
    ‚îú‚îÄ‚îÄ recursive.py     # Recursive text splitter
    ‚îî‚îÄ‚îÄ semantic.py      # Semantic chunking
```
---

### Phase 4: Embeddings & Vector Database
**Timeline:** Weeks 6-7 | **Difficulty:** Intermediate

Embed document chunks and store them in a vector database for retrieval.

**Learning Objectives:**
- How embeddings represent semantic meaning
- Embedding models (OpenAI, sentence-transformers)
- Vector database setup (Chroma ‚Üí Pinecone)
- Similarity search and distance metrics (cosine, euclidean, dot product)
- Index optimization and performance tuning
- Metadata filtering strategies

**Key Files:**
```
src/
‚îú‚îÄ‚îÄ embeddings/
‚îÇ   ‚îú‚îÄ‚îÄ base.py          # Embedding interface
‚îÇ   ‚îú‚îÄ‚îÄ openai.py        # OpenAI embeddings
‚îÇ   ‚îî‚îÄ‚îÄ local.py         # Sentence-transformers
‚îî‚îÄ‚îÄ vectorstore/
    ‚îú‚îÄ‚îÄ base.py          # Vector store interface
    ‚îú‚îÄ‚îÄ chroma.py        # Chroma implementation
    ‚îî‚îÄ‚îÄ pinecone.py      # Pinecone implementation
```
---

### Phase 5: RAG Pipeline
**Timeline:** Weeks 8-10 | **Difficulty:** Intermediate

Build a secure RAG pipeline with guardrails and safety measures.

**Learning Objectives:**
- Retrieval + generation flow
- Context injection into prompts
- Citation and source tracking
- Hallucination reduction techniques
- Input validation and sanitization
- PII detection and handling
- Prompt injection defense
- Output guardrails

**Key Files:**
```
src/
‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îú‚îÄ‚îÄ retriever.py     # Document retrieval
‚îÇ   ‚îú‚îÄ‚îÄ generator.py     # Response generation
‚îÇ   ‚îî‚îÄ‚îÄ chain.py         # RAG chain orchestration
‚îú‚îÄ‚îÄ guardrails/
‚îÇ   ‚îú‚îÄ‚îÄ input.py         # Input validation
‚îÇ   ‚îú‚îÄ‚îÄ pii.py           # PII detection
‚îÇ   ‚îú‚îÄ‚îÄ injection.py     # Prompt injection defense
‚îÇ   ‚îî‚îÄ‚îÄ output.py        # Output validation
‚îî‚îÄ‚îÄ prompts/
    ‚îî‚îÄ‚îÄ rag.py           # RAG-specific prompts
```
---

### Phase 6: Agents & Tools with LangGraph
**Timeline:** Weeks 11-14 | **Difficulty:** Advanced

Build an agent with intent classification and intelligent routing.

**Learning Objectives:**
- Agent architectures (ReAct pattern)
- LangGraph for stateful workflows
- Tool definition and function calling
- Conditional routing and control flow
- State management across interactions
- Intent classification for routing
- When to use agent vs simple RAG

**Key Files:**
```
src/
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ graph.py         # LangGraph definition
‚îÇ   ‚îú‚îÄ‚îÄ state.py         # Agent state schema
‚îÇ   ‚îî‚îÄ‚îÄ nodes.py         # Graph nodes
‚îú‚îÄ‚îÄ routing/
‚îÇ   ‚îú‚îÄ‚îÄ classifier.py    # Intent classification
‚îÇ   ‚îî‚îÄ‚îÄ router.py        # Query routing logic
‚îî‚îÄ‚îÄ tools/
    ‚îú‚îÄ‚îÄ base.py          # Tool interface
    ‚îú‚îÄ‚îÄ search.py        # Knowledge base search
    ‚îú‚îÄ‚îÄ web.py           # Web browsing
    ‚îú‚îÄ‚îÄ code.py          # Code execution
    ‚îî‚îÄ‚îÄ notes.py         # Note taking
```
---

### Phase 7: Advanced Retrieval & Evaluation
**Timeline:** Weeks 15-18 | **Difficulty:** Advanced

Optimize retrieval with caching, model routing, and comprehensive evaluation.

**Learning Objectives:**
- Hybrid search (keyword + semantic)
- Reranking with cross-encoders
- Query transformation (HyDE, multi-query)
- Semantic caching for cost reduction
- Model routing based on complexity
- Evaluation metrics (RAGAS, faithfulness, relevance)
- LLM-as-judge evaluation patterns
- Synthetic data generation for testing
- A/B testing retrieval strategies

**Key Files:**
```
src/
‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îú‚îÄ‚îÄ hybrid.py        # Hybrid search
‚îÇ   ‚îú‚îÄ‚îÄ rerank.py        # Reranking models
‚îÇ   ‚îî‚îÄ‚îÄ transform.py     # Query transformation (HyDE)
‚îú‚îÄ‚îÄ caching/
‚îÇ   ‚îú‚îÄ‚îÄ exact.py         # Exact match cache
‚îÇ   ‚îî‚îÄ‚îÄ semantic.py      # Semantic similarity cache
‚îú‚îÄ‚îÄ routing/
‚îÇ   ‚îî‚îÄ‚îÄ model_router.py  # Model selection logic
‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py       # Evaluation metrics
‚îÇ   ‚îú‚îÄ‚îÄ llm_judge.py     # LLM-as-judge evaluator
‚îÇ   ‚îú‚îÄ‚îÄ synthetic.py     # Synthetic data generation
‚îÇ   ‚îú‚îÄ‚îÄ datasets.py      # Test dataset management
‚îÇ   ‚îî‚îÄ‚îÄ runner.py        # Evaluation runner
‚îî‚îÄ‚îÄ experiments/
    ‚îî‚îÄ‚îÄ ab_testing.py    # A/B testing framework
```

---

### Phase 8: Custom Models & Production
**Timeline:** Weeks 19+ | **Difficulty:** Advanced

Fine-tune embeddings, add local model support, deploy with full observability.

**Learning Objectives:**
- TensorFlow/PyTorch for embedding fine-tuning
- Contrastive learning (triplet loss, InfoNCE)
- Knowledge distillation basics
- Local model deployment (Ollama, vLLM)
- Observability and tracing (Langfuse/LangSmith)
- Caching strategies for performance
- API design with FastAPI
- Containerization and deployment
- Feedback collection and improvement loops
- Cost dashboards and monitoring

**Key Files:**
```
src/
‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py       # Training data preparation
‚îÇ   ‚îú‚îÄ‚îÄ model.py         # Model architecture
‚îÇ   ‚îú‚îÄ‚îÄ losses.py        # Contrastive losses
‚îÇ   ‚îú‚îÄ‚îÄ train.py         # Training loop
‚îÇ   ‚îî‚îÄ‚îÄ distill.py       # Knowledge distillation
‚îú‚îÄ‚îÄ inference/
‚îÇ   ‚îú‚îÄ‚îÄ local.py         # Ollama/vLLM integration
‚îÇ   ‚îî‚îÄ‚îÄ quantization.py  # Model quantization
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ routes/          # API endpoints
‚îÇ   ‚îî‚îÄ‚îÄ middleware/      # Auth, rate limiting
‚îú‚îÄ‚îÄ observability/
‚îÇ   ‚îú‚îÄ‚îÄ tracing.py       # Request tracing
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py       # Performance metrics
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.py     # Cost dashboard
‚îî‚îÄ‚îÄ feedback/
    ‚îú‚îÄ‚îÄ collector.py     # Feedback collection
    ‚îî‚îÄ‚îÄ improver.py      # Feedback-based improvements
```

**Key Concepts:**
```python
# Contrastive learning for embeddings
class ContrastiveLoss(nn.Module):
    def __init__(self, temperature: float = 0.07):
        self.temperature = temperature
    
    def forward(self, anchor, positive, negatives):
        # Compute similarities
        pos_sim = F.cosine_similarity(anchor, positive)
        neg_sims = F.cosine_similarity(
            anchor.unsqueeze(1), 
            negatives, 
            dim=2
        )
        
        # InfoNCE loss
        logits = torch.cat([pos_sim.unsqueeze(1), neg_sims], dim=1)
        logits = logits / self.temperature
        labels = torch.zeros(logits.shape[0], dtype=torch.long)
        
        return F.cross_entropy(logits, labels)

# Feedback loop
class FeedbackCollector:
    def record(self, query: str, response: str, feedback: Feedback):
        self.db.insert({
            "query": query,
            "response": response,
            "rating": feedback.rating,  # thumbs up/down
            "timestamp": now()
        })
    
    def get_improvement_candidates(self) -> list[dict]:
        # Find queries with negative feedback
        return self.db.query(
            "SELECT * FROM feedback WHERE rating = 'negative'"
        )

# Local model integration
class LocalLLM:
    def __init__(self, model: str = "llama3.2"):
        self.client = ollama.Client()
        self.model = model
    
    async def generate(self, prompt: str) -> str:
        response = await self.client.generate(
            model=self.model,
            prompt=prompt
        )
        return response["response"]
```

---

## üõ†Ô∏è Tech Stack

| Category | Technology |
|----------|------------|
| **Language** | Python 3.11+ |
| **LLM (Cloud)** | Anthropic Claude / OpenAI GPT |
| **LLM (Local)** | Ollama, vLLM |
| **Embeddings** | sentence-transformers ‚Üí fine-tuned |
| **Vector DB** | Chroma (local) ‚Üí Pinecone (production) |
| **Agents** | LangGraph |
| **Training** | TensorFlow / PyTorch |
| **API** | FastAPI |
| **Observability** | Langfuse, Prometheus, Grafana |
| **Caching** | Redis |

---

## üìÅ Project Structure

```
second-brain/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ chat.py
‚îÇ   ‚îú‚îÄ‚îÄ memory.py
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ markdown.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ batch.py
‚îÇ   ‚îú‚îÄ‚îÄ chunking/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fixed.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ recursive.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ semantic.py
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ local.py
‚îÇ   ‚îú‚îÄ‚îÄ vectorstore/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chroma.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pinecone.py
‚îÇ   ‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chain.py
‚îÇ   ‚îú‚îÄ‚îÄ guardrails/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pii.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ injection.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output.py
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nodes.py
‚îÇ   ‚îú‚îÄ‚îÄ routing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_router.py
‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ code.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ notes.py
‚îÇ   ‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rerank.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transform.py
‚îÇ   ‚îú‚îÄ‚îÄ caching/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exact.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ semantic.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_judge.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ synthetic.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ datasets.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ runner.py
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ losses.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ distill.py
‚îÇ   ‚îú‚îÄ‚îÄ inference/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quantization.py
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes/
‚îÇ   ‚îú‚îÄ‚îÄ observability/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tracing.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard.py
‚îÇ   ‚îú‚îÄ‚îÄ feedback/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collector.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ improver.py
‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs.py
‚îÇ   ‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ templates.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ streaming.py
‚îÇ       ‚îú‚îÄ‚îÄ retry.py
‚îÇ       ‚îú‚îÄ‚îÄ tokens.py
‚îÇ       ‚îî‚îÄ‚îÄ costs.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/
‚îú‚îÄ‚îÄ notebooks/               # Experimentation notebooks
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Original documents
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Chunked documents
‚îÇ   ‚îî‚îÄ‚îÄ eval/               # Evaluation datasets
‚îú‚îÄ‚îÄ models/                 # Trained models
‚îú‚îÄ‚îÄ configs/                # Configuration files
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Getting Started

### Prerequisites

- Python 3.11+
- An API key for Anthropic or OpenAI
- Docker (optional, for local models)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/second-brain.git
cd second-brain

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys
```

### Quick Start

```bash
# Run the basic chat (Phase 1)
python -m src.chat

# Run the RAG pipeline (Phase 5+)
python -m src.rag.chain

# Run the agent (Phase 6+)
python -m src.agents.graph

# Start the API server (Phase 8)
uvicorn src.api.main:app --reload

# Run with local models (Phase 8)
docker-compose up ollama
python -m src.inference.local
```

---

## üìä Evaluation Results

*Results will be added as phases are completed.*

| Metric | Baseline | Current | Target |
|--------|----------|---------|--------|
| Retrieval Recall@5 | - | - | >0.85 |
| Answer Faithfulness | - | - | >0.90 |
| Answer Relevance | - | - | >0.85 |
| Latency (p95) | - | - | <2s |
| Cache Hit Rate | - | - | >40% |
| Cost per Query | - | - | <$0.01 |

---

## üí∞ Cost Tracking

*Will be populated as the project progresses.*

| Model | Queries | Tokens | Cost |
|-------|---------|--------|------|
| Claude Haiku | - | - | - |
| Claude Sonnet | - | - | - |
| Local (Ollama) | - | - | $0 |
| **Total** | - | - | - |

---

## üìù What I Learned

*This section documents key learnings from each phase.*

### Phase 1: Basic Chat API
- *Coming soon...*

### Phase 2: Prompt Engineering & Memory
- *Coming soon...*

### Phase 3: Document Ingestion & Chunking
- *Coming soon...*

### Phase 4: Embeddings & Vector Database
- *Coming soon...*

### Phase 5: RAG Pipeline
- *Coming soon...*

### Phase 6: Agents & Tools
- *Coming soon...*

### Phase 7: Advanced Retrieval & Evaluation
- *Coming soon...*

### Phase 8: Custom Models & Production
- *Coming soon...*

---

## üß™ Running Tests

```bash
# Unit tests
pytest tests/unit

# Integration tests
pytest tests/integration

# Evaluation tests
pytest tests/evaluation

# All tests with coverage
pytest --cov=src tests/
```
---

<p align="center">
  Built with ‚ù§Ô∏è as a comprehensive journey through AI Engineering
</p>
